\chapter {Parameterization theorem}
\newcommand{\smn}{$S_n^m$}

We'll start by giving an intuition on what the theorem talks
about. Let $f : \nat^2 \rightarrow \nat$ be a computable
function. Surely there exists an indice (to be precise infinitely many
of them) $\ell$ s.t. \[f(x,y) = \varphi_\ell^{(2)}(x,y)\]

Now, if we fix the first argument to a certain value $x$, we obtain a
function of a single argument $f_x : \nattonat$
\[f_x(y) = \varphi_\ell^{(2)}(x,y)\] and $\forall x \in \nat, \; f_x$
is computable (since obtained from composition of computable
funcitons. This means that exists a $d \in \nat$ s.t.
\[f_x = \varphi_d\] in other words, $\forall y \in \nat$
\[f_x(y) = \varphi_\ell^{(2)}(x,y) = \varphi_d(y)\] Clearly $d$
depends on $\ell$ and $x$, since $d = S(\ell, x)$ with
$S : \nat^2 \rightarrow \nat$ total function. The \smn
(\textit{smn}) theorem tells us that $S$ is computable. Intuitively,
how can I compute $S(\ell, x)$?

\begin{itemize}
\item form $\ell$ I can determine the program
  $P_\ell = \gamma^{-1}(\ell)$ that computes $\varphi_\ell^{(2)}(x,y)$
\item the program that computes $f_x = \lambda y \; . \; f(x,y)$ with
  $x$ fixed we can easly obtain from $P_\ell$:
  \begin{itemize}
  \item move $y$ in the register 2;
  \item put $x$ in the register 1;
  \item execute $P_\ell$
  \end{itemize}
\item we take the code of the obtained program
\end{itemize}

Again, intuitively, funcitons on indices, like $S$ are functions that
transform programs. The \smn theorem states that the operation of
fixing an argument of a program is effective.

\begin{example}
  Consider the computable function \[f(x,y) = x^y\]. We know that an
  indices s.t. \(\varphi_ell = f\) must exist, in other
  words \[\varphi_\ell(x,y) = f(x,y) = x^y\] So, when $x$ varies we
  obtain computable functions
  \begin{itemize}
  \item[] \(f_0(y) = y^0 = 1 \rightarrow \mbox{ indice} \quad S(\ell,0)\)
  \item[] \(f_1(y) = y^1 = y \rightarrow \mbox{ indice} \quad S(\ell,1)\)
  \item[] \(f_2(y) = y^2 = y^2 \rightarrow \mbox{ indice} \quad S(\ell,2)\)
  \item[] \(\dots\)
  \end{itemize}
  thanks to the \smn theorem we can determine those indices in an
  effective way. The thoerem also does this in general for functions
  in the form $f(\vec{x}, \vec{y}) : \nat^{(m+n)} \rightarrow \nat$,
  hence the name.
\end{example}

\begin{theorem}[\smn theorem]
  Given $m, n \geq 1$ exists a computable total function
  \[S_{m,n} : \nat^{m+1} \rightarrow \nat\] s.t.

  \[
    \varphi_\ell^{(m+n)}(\vec{x},\vec{y}) = \varphi_{s_{m,n}(\ell,
      \vec{x})}^{(n)}(\vec{y}) \quad \forall \ell \in \nat, \; x \in
    \nat^m, y \in \nat^n
  \]

  \begin{proof}
    intuitively, given $\ell \in \nat$, $\vec{x}\in \nat^m$ we can:
    \begin{itemize}
    \item with $\gamma^{-1}$ obtain the program
      $P_\ell = \gamma^{-1}(\ell)$ in standard form that computes the
      function $\varphi_\ell^{(m+n)}$, that is to say that starting
      from ( $\vec{x}, \vec{y}$ occupying respectively $m$ and $n$
      registers)
      \[
        \begin{tabu}{|c|c|c|c|c}
          \hline
          \vec{x} & \vec{y} & 0 & 0 & \dots \\ \hline
        \end{tabu}
        \quad \quad \mbox{it computes }
        \varphi_\ell^{(m+n)}(\vec{x},\vec{y})
      \]
    \item starting from $P_\ell$ we can build a new program $P$ tht
      starting from
      \[
        \begin{tabu}{|c|c|c|c}
          \hline
          \vec{y} & 0 & 0 & \dots \\ \hline
        \end{tabu}
        \quad \quad \mbox{it computes }
        \varphi_\ell^{(m+n)}(\vec{x},\vec{y})
      \]
    \end{itemize}

    In fact, it is sufficent
    \begin{itemize}
    \item move $\vec{y}$ ``forward'' of $m$ registers
    \item load $\vec{x}$ in the free $m$ registers
    \item execute $P_\ell$
    \end{itemize}
    
    The program P can be

    \begin{center}
      \begin{tabular}{lr}
        $T([1,n], [m+1, m+n])$    &          \\
        $z(n)$                    &          \\
        $s(n)$                    &          \\
        $\dots$                   & \comment{$x_1$ times} \\
        $z(m)$                    &          \\
        $s(m)$                    &          \\
        $\dots$                   & \comment{$x_m$ times}
      \end{tabular}
    \end{center}
    (\textbf{Reminder:} the concatenation has to update all the jump
    instrutions in $P_\ell$,
    $j(m^\prime, n^\prime, t) \rightsquigarrow j(m^\prime, n^\prime, t
    + m + n + \sum_{i=1}^mx_i)$

    Once we have build $P$ we can say that
    \[S(\ell, \vec{x}) = \gamma(P)\] Each function and construction
    method used are effective (in particular $\gamma, \gamma^{-1}$
    are) and so the existence, totality and computability of $S$ are
    proved (even if informally, by appealing to the Church-Turing
    thesis.
  \end{proof}
\end{theorem}
% Again, here he goes very fast, where in the notes he approaches it
% with more calm

% Suppose we have a computable function $ f:\nat^2\rightarrow\nat$
% therefore $ \exists e \in \nat . f = \phi_e^{(2)} $, now consider for
% the first fixed argument: $ f(x,y) = f_x(y) $, where
% $ f_x:\nat\rightarrow\nat $ computable, therefore there is a program
% that calculates it.

% For example let's take $ f(x,y) = y^x $ then $ f_0(y) = 1 $, \dots all
% these functions are computable.

% We had the program that computed $ f(x,y) = \phi_e^{(x)}(x,y) $, so
% there is some program $d$ that calculates $ f_x = \phi_d $, but
% obviously they are all different programs for each $d$. We observe
% that this program depends on \textit{e} and on \textit{x}.

% What we are saying is that there exists total
% $ s:\nat^2\rightarrow\nat$ such that
% $ \phi_{s(e,x)}(y) = \phi_e^{(2)}(x,y)$, the theorem says it is
% computable. In general we can take a function of $ m+n $ arguments,
% $ m,n \in \nat $, $ m,n \geq 1 $ there exists
% $ S_{m,n} : \nat^{m+1}\rightarrow\nat \in \mathcal{PR}$
% s.t.

% \begin{equation*}
%   \phi_e^{m+n}(\vec{x},\vec{y}) = \phi_{s_{m,n}(e, \vec{x})}^{n}(\vec{y})
% \end{equation*}

% But now let's see how to calculate $ \gamma $. First we define
% function $ agg:\nat^2\rightarrow\nat $ where $ agg(e,t) =$ program
% obtained by \textit{e} adding \textit{t} to the destination of each
% jump.

% Now let's take $ \overline{agg} $ where $ \overline{agg}(i,t) = $
% update of instruction i (meaning $ \beta^{-1}(i) $)

% \dots

% \section {Corollary SMN theorem}
% Given the function
% $ f:\nat^{n+m}\rightarrow\nat,\\ \exists S:\nat^m\rightarrow\nat $
% total computable s.t.
% $ f(\vec{x},\vec{y}) = \phi_{s(\vec{x})}^{(n)}(\vec{y}) \forall
% \vec{x},\vec{y}$

% \section {Exercise}

% Show that there exists $s$ total computable s.t.
% $ \phi_{s(n)}(x) = \sqrt[n]{x} $

% \textbf{Execution:} I take the function $ f(n,x) = \sqrt[n]{x} $ so I
% have to search \\ $ max(y) . y^n \leq x $, but I can only use the
% minimum, so I try $ min(y). (y+1)^n > x $

% that is: $ \mu y \leq x . x+1 - (y+1)^n $. Even without bound it
% worked, but so we also show that it is recursive primitive (it was not
% required).

% We see that it is computable, therefore by corollary of the smn
% theorem there exists the total computable function $s$ such that
% $ f(n,x) = \phi_{s(n)}(x) $.
